{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a href=\"https://cognitiveclass.ai\"><img src=\"https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/IBMDeveloperSkillsNetwork-DL0101EN-SkillsNetwork/images/IDSN-logo.png\" width=\"400\"> </a>\n",
    "\n",
    "# Transformers with Keras\n",
    "\n",
    "Estimated time needed **45** mins\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this lab, we will learn how to use the Keras library to build a transformer using a sequence-to-sequence architecture with self-attention for translation. We will train the model using a sample dataset and then use this model for English to Spanish translation.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Objectives for this Notebook    \n",
    "* How to use the Keras library to build transformers model\n",
    "* Train the transformer model using a given dataset\n",
    "* Use the trained transformer model to translate\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Table of Contents</h2>\n",
    "\n",
    "\n",
    "<div class=\"alert alert-block alert-info\" style=\"margin-top: 20px\">\n",
    "\n",
    "<font size = 4>\n",
    "1. <a href=\"#Import-Keras-and-Packages\">Import Keras and Packages</a><br>\n",
    "2. <a href=\"#Step-1:-Data-Preparation\">Step 1: Data Preparation</a><br>\n",
    "3. <a href=\"#Step-2:-Self-Attention-Layer\">Step 2: Self-Attention Layer</a><br>\n",
    "4. <a href=\"#Step-3:-Model-Architecture\">Step 3: Model Architecture</a><br>\n",
    "5. <a href=\"#Step-4:-Training-the-Model\">Step 4: Training the Model</a><br>\n",
    "6. <a href=\"#Step-5:-Plotting-the-training-loss\">Step 5: Plotting the training loss</a><br>\n",
    "\n",
    "</font>\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Keras and Packages\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's start by importing the keras libraries and the packages that we would need to build a neural network.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following required libraries are __not__ pre-installed in the Skills Network Labs environment. __You will need to run the following cell__ to install them:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Collecting tensorflow_cpu==2.17.1\n",
      "  Downloading tensorflow_cpu-2.17.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (221.2 MB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m221.2/221.2 MB\u001b[0m \u001b[31m870.9 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mm eta \u001b[36m0:00:01\u001b[0m[36m0:00:08\u001b[0m\n",
      "Requirement already satisfied: libclang>=13.0.0 in /home/srabon/.local/lib/python3.10/site-packages (from tensorflow_cpu==2.17.1) (18.1.1)\n",
      "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /home/srabon/.local/lib/python3.10/site-packages (from tensorflow_cpu==2.17.1) (0.6.0)\n",
      "Requirement already satisfied: six>=1.12.0 in /usr/lib/python3/dist-packages (from tensorflow_cpu==2.17.1) (1.16.0)\n",
      "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /home/srabon/.local/lib/python3.10/site-packages (from tensorflow_cpu==2.17.1) (0.37.1)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in /home/srabon/.local/lib/python3.10/site-packages (from tensorflow_cpu==2.17.1) (4.12.2)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /home/srabon/.local/lib/python3.10/site-packages (from tensorflow_cpu==2.17.1) (1.76.0)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in /home/srabon/.local/lib/python3.10/site-packages (from tensorflow_cpu==2.17.1) (0.2.0)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in /home/srabon/.local/lib/python3.10/site-packages (from tensorflow_cpu==2.17.1) (3.4.0)\n",
      "Collecting numpy<2.0.0,>=1.23.5\n",
      "  Using cached numpy-1.26.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (18.2 MB)\n",
      "Requirement already satisfied: packaging in /home/srabon/.local/lib/python3.10/site-packages (from tensorflow_cpu==2.17.1) (24.2)\n",
      "Collecting tensorboard<2.18,>=2.17\n",
      "  Downloading tensorboard-2.17.1-py3-none-any.whl (5.5 MB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.5/5.5 MB\u001b[0m \u001b[31m689.1 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mm eta \u001b[36m0:00:01\u001b[0m[36m0:00:01\u001b[0m\n",
      "Requirement already satisfied: setuptools in /usr/lib/python3/dist-packages (from tensorflow_cpu==2.17.1) (59.6.0)\n",
      "Requirement already satisfied: flatbuffers>=24.3.25 in /home/srabon/.local/lib/python3.10/site-packages (from tensorflow_cpu==2.17.1) (25.9.23)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in /home/srabon/.local/lib/python3.10/site-packages (from tensorflow_cpu==2.17.1) (2.32.3)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in /home/srabon/.local/lib/python3.10/site-packages (from tensorflow_cpu==2.17.1) (1.6.3)\n",
      "Requirement already satisfied: ml-dtypes<0.5.0,>=0.3.1 in /home/srabon/.local/lib/python3.10/site-packages (from tensorflow_cpu==2.17.1) (0.4.1)\n",
      "Requirement already satisfied: h5py>=3.10.0 in /home/srabon/.local/lib/python3.10/site-packages (from tensorflow_cpu==2.17.1) (3.15.1)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in /home/srabon/.local/lib/python3.10/site-packages (from tensorflow_cpu==2.17.1) (2.3.1)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in /home/srabon/.local/lib/python3.10/site-packages (from tensorflow_cpu==2.17.1) (2.0.1)\n",
      "Requirement already satisfied: keras>=3.2.0 in /home/srabon/.local/lib/python3.10/site-packages (from tensorflow_cpu==2.17.1) (3.12.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in /home/srabon/.local/lib/python3.10/site-packages (from tensorflow_cpu==2.17.1) (3.2.0)\n",
      "Collecting protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3\n",
      "  Downloading protobuf-4.25.8-cp37-abi3-manylinux2014_x86_64.whl (294 kB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m294.9/294.9 KB\u001b[0m \u001b[31m821.3 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m1m984.2 kB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/lib/python3/dist-packages (from astunparse>=1.6.0->tensorflow_cpu==2.17.1) (0.37.1)\n",
      "Requirement already satisfied: optree in /home/srabon/.local/lib/python3.10/site-packages (from keras>=3.2.0->tensorflow_cpu==2.17.1) (0.18.0)\n",
      "Requirement already satisfied: namex in /home/srabon/.local/lib/python3.10/site-packages (from keras>=3.2.0->tensorflow_cpu==2.17.1) (0.1.0)\n",
      "Requirement already satisfied: rich in /home/srabon/.local/lib/python3.10/site-packages (from keras>=3.2.0->tensorflow_cpu==2.17.1) (14.0.0)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/lib/python3/dist-packages (from requests<3,>=2.21.0->tensorflow_cpu==2.17.1) (1.26.5)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/srabon/.local/lib/python3.10/site-packages (from requests<3,>=2.21.0->tensorflow_cpu==2.17.1) (3.4.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/lib/python3/dist-packages (from requests<3,>=2.21.0->tensorflow_cpu==2.17.1) (2020.6.20)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/lib/python3/dist-packages (from requests<3,>=2.21.0->tensorflow_cpu==2.17.1) (3.3)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /home/srabon/.local/lib/python3.10/site-packages (from tensorboard<2.18,>=2.17->tensorflow_cpu==2.17.1) (3.10)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /home/srabon/.local/lib/python3.10/site-packages (from tensorboard<2.18,>=2.17->tensorflow_cpu==2.17.1) (0.7.2)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in /home/srabon/.local/lib/python3.10/site-packages (from tensorboard<2.18,>=2.17->tensorflow_cpu==2.17.1) (3.1.4)\n",
      "Requirement already satisfied: markupsafe>=2.1.1 in /home/srabon/.local/lib/python3.10/site-packages (from werkzeug>=1.0.1->tensorboard<2.18,>=2.17->tensorflow_cpu==2.17.1) (3.0.3)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in /home/srabon/.local/lib/python3.10/site-packages (from rich->keras>=3.2.0->tensorflow_cpu==2.17.1) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /home/srabon/.local/lib/python3.10/site-packages (from rich->keras>=3.2.0->tensorflow_cpu==2.17.1) (2.19.1)\n",
      "Requirement already satisfied: mdurl~=0.1 in /home/srabon/.local/lib/python3.10/site-packages (from markdown-it-py>=2.2.0->rich->keras>=3.2.0->tensorflow_cpu==2.17.1) (0.1.2)\n",
      "Installing collected packages: protobuf, numpy, tensorboard, tensorflow_cpu\n",
      "  Attempting uninstall: protobuf\n",
      "    Found existing installation: protobuf 5.29.6\n",
      "    Uninstalling protobuf-5.29.6:\n",
      "      Successfully uninstalled protobuf-5.29.6\n",
      "  Attempting uninstall: numpy\n",
      "    Found existing installation: numpy 2.0.2\n",
      "    Uninstalling numpy-2.0.2:\n",
      "      Successfully uninstalled numpy-2.0.2\n",
      "  Attempting uninstall: tensorboard\n",
      "    Found existing installation: tensorboard 2.18.0\n",
      "    Uninstalling tensorboard-2.18.0:\n",
      "      Successfully uninstalled tensorboard-2.18.0\n",
      "  Attempting uninstall: tensorflow_cpu\n",
      "    Found existing installation: tensorflow_cpu 2.18.0\n",
      "    Uninstalling tensorflow_cpu-2.18.0:\n",
      "      Successfully uninstalled tensorflow_cpu-2.18.0\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "tensorflow 2.20.0 requires ml_dtypes<1.0.0,>=0.5.1, but you have ml-dtypes 0.4.1 which is incompatible.\n",
      "tensorflow 2.20.0 requires protobuf>=5.28.0, but you have protobuf 4.25.8 which is incompatible.\n",
      "tensorflow 2.20.0 requires tensorboard~=2.20.0, but you have tensorboard 2.17.1 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed numpy-1.26.4 protobuf-4.25.8 tensorboard-2.17.1 tensorflow_cpu-2.17.1\n",
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: matplotlib==3.9.2 in /home/srabon/.local/lib/python3.10/site-packages (3.9.2)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /home/srabon/.local/lib/python3.10/site-packages (from matplotlib==3.9.2) (2.9.0.post0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /home/srabon/.local/lib/python3.10/site-packages (from matplotlib==3.9.2) (3.2.5)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /home/srabon/.local/lib/python3.10/site-packages (from matplotlib==3.9.2) (4.56.0)\n",
      "Requirement already satisfied: packaging>=20.0 in /home/srabon/.local/lib/python3.10/site-packages (from matplotlib==3.9.2) (24.2)\n",
      "Requirement already satisfied: numpy>=1.23 in /home/srabon/.local/lib/python3.10/site-packages (from matplotlib==3.9.2) (1.26.4)\n",
      "Requirement already satisfied: cycler>=0.10 in /home/srabon/.local/lib/python3.10/site-packages (from matplotlib==3.9.2) (0.12.1)\n",
      "Requirement already satisfied: pillow>=8 in /home/srabon/.local/lib/python3.10/site-packages (from matplotlib==3.9.2) (11.1.0)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in /home/srabon/.local/lib/python3.10/site-packages (from matplotlib==3.9.2) (1.4.8)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /home/srabon/.local/lib/python3.10/site-packages (from matplotlib==3.9.2) (1.3.1)\n",
      "Requirement already satisfied: six>=1.5 in /usr/lib/python3/dist-packages (from python-dateutil>=2.7->matplotlib==3.9.2) (1.16.0)\n",
      "==== All required libraries are installed =====\n"
     ]
    }
   ],
   "source": [
    "!pip install tensorflow_cpu==2.17.1\n",
    "!pip install matplotlib==3.9.2\n",
    "\n",
    "print(\"==== All required libraries are installed =====\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Suppress the tensorflow warning messages\n",
    "We use the following code to  suppress the warning messages due to use of CPU architechture for tensoflow.\n",
    "\n",
    "You may want to **comment out** these lines if you are using the GPU architechture\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['TF_ENABLE_ONEDNN_OPTS'] = '0'\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### To use Keras, you will also need to install a backend framework – such as TensorFlow.\n",
    "\n",
    "If you install TensorFlow 2.16 or above, it will install Keras by default.\n",
    "\n",
    "We are using the CPU version of tensorflow since we are dealing with smaller datasets. \n",
    "You may install the GPU version of tensorflow on your machine to accelarate the processing of larger datasets\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import the necessary libraries\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from keras.models import Model\n",
    "from keras.layers import Input, LSTM, Dense, Embedding, Dropout\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras import backend as K\n",
    "from keras.layers import Layer\n",
    "import warnings\n",
    "warnings.simplefilter('ignore', FutureWarning)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 1: Data Preparation\n",
    "We start by define the sentences and text for translation training\n",
    "Sentence Pairs: Defines a small dataset of English-Spanish sentence pairs.\n",
    "Target Sequences:\n",
    "Prepends \"startseq\" and appends \"endseq\" to each target sentence for the decoder to learn when to start and stop translating.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sample parallel sentences (English -> Spanish)\n",
    "input_texts = [\n",
    "    \"Hello.\", \"How are you?\", \"I am learning machine translation.\", \"What is your name?\", \"I love programming.\"\n",
    "]\n",
    "target_texts = [\n",
    "    \"Hola.\", \"¿Cómo estás?\", \"Estoy aprendiendo traducción automática.\", \"¿Cuál es tu nombre?\", \"Me encanta programar.\"\n",
    "]\n",
    "\n",
    "target_texts = [\"startseq \" + x + \" endseq\" for x in target_texts]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['startseq Hola. endseq',\n",
       " 'startseq ¿Cómo estás? endseq',\n",
       " 'startseq Estoy aprendiendo traducción automática. endseq',\n",
       " 'startseq ¿Cuál es tu nombre? endseq',\n",
       " 'startseq Me encanta programar. endseq']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target_texts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Next, we convert the text from the sentences to tokens and create a vocabulary\n",
    "Tokenization: Uses Tokenizer to convert words into numerical sequences.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tokenization\n",
    "input_tokenizer = Tokenizer()\n",
    "input_tokenizer.fit_on_texts(input_texts)\n",
    "input_sequences = input_tokenizer.texts_to_sequences(input_texts)\n",
    "\n",
    "output_tokenizer = Tokenizer()\n",
    "output_tokenizer.fit_on_texts(target_texts)\n",
    "output_sequences = output_tokenizer.texts_to_sequences(target_texts)\n",
    "\n",
    "input_vocab_size = len(input_tokenizer.word_index) + 1\n",
    "output_vocab_size = len(output_tokenizer.word_index) + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[1, 3, 2],\n",
       " [1, 4, 5, 2],\n",
       " [1, 6, 7, 8, 9, 2],\n",
       " [1, 10, 11, 12, 13, 2],\n",
       " [1, 14, 15, 16, 2]]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[2], [3, 4, 5], [1, 6, 7, 8, 9], [10, 11, 12, 13], [1, 14, 15]]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_sequences"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now pad the corresponding sentences\n",
    "Padding: Ensures all sequences have the same length.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Padding\n",
    "max_input_length = max([len(seq) for seq in input_sequences])\n",
    "max_output_length = max([len(seq) for seq in output_sequences])\n",
    "\n",
    "input_sequences = pad_sequences(input_sequences, maxlen=max_input_length, padding='post')\n",
    "output_sequences = pad_sequences(output_sequences, maxlen=max_output_length, padding='post')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 2,  0,  0,  0,  0],\n",
       "       [ 3,  4,  5,  0,  0],\n",
       "       [ 1,  6,  7,  8,  9],\n",
       "       [10, 11, 12, 13,  0],\n",
       "       [ 1, 14, 15,  0,  0]], dtype=int32)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare the target data for training\n",
    "decoder_input_data = output_sequences[:, :-1]\n",
    "decoder_output_data = output_sequences[:, 1:]\n",
    "\n",
    "# Convert to one-hot\n",
    "decoder_output_data = np.array([np.eye(output_vocab_size)[seq] for seq in decoder_output_data])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0.],\n",
       "        [0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0.],\n",
       "        [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0.],\n",
       "        [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0.],\n",
       "        [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0.]],\n",
       "\n",
       "       [[0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0.],\n",
       "        [0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0.],\n",
       "        [0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0.],\n",
       "        [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0.],\n",
       "        [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0.]],\n",
       "\n",
       "       [[0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.,\n",
       "         0.],\n",
       "        [0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0.]],\n",
       "\n",
       "       [[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.,\n",
       "         0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
       "         0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
       "         0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
       "         0.],\n",
       "        [0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0.]],\n",
       "\n",
       "       [[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "         0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
       "         0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         1.],\n",
       "        [0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0.],\n",
       "        [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0.]]])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decoder_output_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 2: Self-Attention Layer\n",
    "Self-attention is a mechanism that allows a model to **focus on relevant parts of the input sequence** while processing each word. This is particularly useful in:\n",
    "1) Machine Translation (e.g., aligning words correctly)\n",
    "2) Text Summarization\n",
    "3) Speech Recognition\n",
    "4) Image Processing (Vision Transformers)\n",
    "In this implementation, self-attention is used for text based sequence-to-sequence modeling.\n",
    "\n",
    "\n",
    "Self-Attention works for a given an input sequence by computing a weighted representation of all words for each position. It does so using three key components:\n",
    "\n",
    "1. Query **(Q)**, Key **(K)**, and Value **(V)** Matrices\n",
    "For each word (token) in a sequence:\n",
    "\n",
    "Query (Q): What this word is looking for.\n",
    "Key (K): What this word represents.\n",
    "Value (V): The actual information in the word.\n",
    "\n",
    "2. Compute **Attention Scores**\n",
    "Next, we **calculate the similarity between each query and key** using dot-product attention:\n",
    "Each word in a sequence attends to every other word based on these scores.\n",
    "\n",
    "3. Apply **Scaling & Softmax**\n",
    "Since dot-product values can be large, we scale them. \n",
    "Next, Applying softmax converts scores into attention weights:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Self-Attention class\n",
    "In this implementation of self-attention layer:\n",
    "1. We first initialize the weights in the **build** method, where:\n",
    "    1. **self.Wq**, **self.Wk**, **self.Wv** are the trainable weight matrices.\n",
    "    2. Their **shape is (feature_dim, feature_dim)**, meaning they transform input features into Q, K, and V representations.\n",
    "2. Applying Attention using **call** method. The **call()** method:\n",
    "   1. Computes **Q, K, V** by multiplying inputs (encoder/decoder output) with their respective weight matrices.\n",
    "   2. Computes **dot-product attention scores** using K.batch_dot(q, k, axes=[2, 2]), resulting in a (batch_size, seq_len, seq_len) matrix.\n",
    "   3. **Scales** the scores to avoid large values.\n",
    "   4. Applies **softmax** to normalize the attention scores.\n",
    "   5. **Multiplies attention weights with V** to get the final output.\n",
    "3. The **compute_output_shape** method defines the shape of the output tensor after the layer processes an input.\n",
    "    1. The output shape of the Self-Attention layer **remains the same** as the input shape.\n",
    "    2. The attention mechanism **transforms** the input but does not change its dimensions.4\n",
    "    3. If the attention layer changed the shape, you would modify compute_output_shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Layer\n",
    "from tensorflow.keras import backend as K\n",
    "\n",
    "class SelfAttention(Layer):\n",
    "    def __init__(self, **kwargs):\n",
    "        super(SelfAttention, self).__init__(**kwargs)\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        # input_shape is a list: [q_shape, k_shape, v_shape]\n",
    "        feature_dim = input_shape[0][-1]\n",
    "\n",
    "        self.Wq = self.add_weight(\n",
    "            shape=(feature_dim, feature_dim),\n",
    "            initializer='glorot_uniform',\n",
    "            trainable=True,\n",
    "            name='Wq'\n",
    "        )\n",
    "\n",
    "        self.Wk = self.add_weight(\n",
    "            shape=(feature_dim, feature_dim),\n",
    "            initializer='glorot_uniform',\n",
    "            trainable=True,\n",
    "            name='Wk'\n",
    "        )\n",
    "\n",
    "        self.Wv = self.add_weight(\n",
    "            shape=(feature_dim, feature_dim),\n",
    "            initializer='glorot_uniform',\n",
    "            trainable=True,\n",
    "            name='Wv'\n",
    "        )\n",
    "\n",
    "        super(SelfAttention, self).build(input_shape)\n",
    "\n",
    "    def call(self, inputs):\n",
    "        # Expect list: [query, key, value]\n",
    "        q, k, v = inputs\n",
    "\n",
    "        q = K.dot(q, self.Wq)\n",
    "        k = K.dot(k, self.Wk)\n",
    "        v = K.dot(v, self.Wv)\n",
    "\n",
    "        # Scaled dot-product attention\n",
    "        scores = K.batch_dot(q, k, axes=[2, 2])\n",
    "        dk = K.cast(K.shape(k)[-1], dtype=K.floatx())\n",
    "        scores = scores / K.sqrt(dk)\n",
    "\n",
    "        attention_weights = K.softmax(scores, axis=-1)\n",
    "        output = K.batch_dot(attention_weights, v)\n",
    "\n",
    "        return output\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 3: Model Architecture\n",
    "The model follows an Encoder-Decoder structure:\n",
    "\n",
    "### Encoder:\n",
    "1) Takes input sentences (padded and tokenized).\n",
    "2) Uses an Embedding layer (word representations) + LSTM (to process sequences).\n",
    "    1. The LSTMs are used as the **help process variable-length input sentences** and generate meaningful translations.\n",
    "4) Outputs context vectors (hidden & cell states).\n",
    "\n",
    "### Attention Layer\n",
    "1) Applied to both the encoder and decoder outputs.\n",
    "2) Helps the decoder focus on relevant words during translation.\n",
    "\n",
    "### Decoder\n",
    "1) Receives target sequences (shifted one step ahead).\n",
    "2) Uses an LSTM with encoder states as initial states.\n",
    "3) Applies self-attention for better learning.\n",
    "4) Uses a Dense layer (Softmax) to predict the next word.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"functional\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)        </span>┃<span style=\"font-weight: bold\"> Output Shape      </span>┃<span style=\"font-weight: bold\">    Param # </span>┃<span style=\"font-weight: bold\"> Connected to      </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
       "│ input_layer         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>)         │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ input_layer_1       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>)         │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ embedding           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)    │      <span style=\"color: #00af00; text-decoration-color: #00af00\">4,096</span> │ input_layer[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>] │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)         │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ embedding_1         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)    │      <span style=\"color: #00af00; text-decoration-color: #00af00\">4,352</span> │ input_layer_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)         │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ lstm (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)         │ [(<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>),  │    <span style=\"color: #00af00; text-decoration-color: #00af00\">525,312</span> │ embedding[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
       "│                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>),      │            │                   │\n",
       "│                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)]      │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ lstm_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)       │ [(<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>),  │    <span style=\"color: #00af00; text-decoration-color: #00af00\">525,312</span> │ embedding_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>… │\n",
       "│                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>),      │            │ lstm[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>],       │\n",
       "│                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)]      │            │ lstm[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>]        │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ self_attention      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)    │    <span style=\"color: #00af00; text-decoration-color: #00af00\">196,608</span> │ lstm_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],     │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">SelfAttention</span>)     │                   │            │ lstm[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],       │\n",
       "│                     │                   │            │ lstm[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]        │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ concatenate         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ lstm_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],     │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Concatenate</span>)       │                   │            │ self_attention[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">17</span>)     │      <span style=\"color: #00af00; text-decoration-color: #00af00\">8,721</span> │ concatenate[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>] │\n",
       "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m   Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to     \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
       "│ input_layer         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m5\u001b[0m)         │          \u001b[38;5;34m0\u001b[0m │ -                 │\n",
       "│ (\u001b[38;5;33mInputLayer\u001b[0m)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ input_layer_1       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m5\u001b[0m)         │          \u001b[38;5;34m0\u001b[0m │ -                 │\n",
       "│ (\u001b[38;5;33mInputLayer\u001b[0m)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ embedding           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m5\u001b[0m, \u001b[38;5;34m256\u001b[0m)    │      \u001b[38;5;34m4,096\u001b[0m │ input_layer[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m] │\n",
       "│ (\u001b[38;5;33mEmbedding\u001b[0m)         │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ embedding_1         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m5\u001b[0m, \u001b[38;5;34m256\u001b[0m)    │      \u001b[38;5;34m4,352\u001b[0m │ input_layer_1[\u001b[38;5;34m0\u001b[0m]… │\n",
       "│ (\u001b[38;5;33mEmbedding\u001b[0m)         │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ lstm (\u001b[38;5;33mLSTM\u001b[0m)         │ [(\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m5\u001b[0m, \u001b[38;5;34m256\u001b[0m),  │    \u001b[38;5;34m525,312\u001b[0m │ embedding[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
       "│                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m),      │            │                   │\n",
       "│                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)]      │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ lstm_1 (\u001b[38;5;33mLSTM\u001b[0m)       │ [(\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m5\u001b[0m, \u001b[38;5;34m256\u001b[0m),  │    \u001b[38;5;34m525,312\u001b[0m │ embedding_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m… │\n",
       "│                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m),      │            │ lstm[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m1\u001b[0m],       │\n",
       "│                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)]      │            │ lstm[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m2\u001b[0m]        │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ self_attention      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m5\u001b[0m, \u001b[38;5;34m256\u001b[0m)    │    \u001b[38;5;34m196,608\u001b[0m │ lstm_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],     │\n",
       "│ (\u001b[38;5;33mSelfAttention\u001b[0m)     │                   │            │ lstm[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],       │\n",
       "│                     │                   │            │ lstm[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]        │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ concatenate         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m5\u001b[0m, \u001b[38;5;34m512\u001b[0m)    │          \u001b[38;5;34m0\u001b[0m │ lstm_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],     │\n",
       "│ (\u001b[38;5;33mConcatenate\u001b[0m)       │                   │            │ self_attention[\u001b[38;5;34m0\u001b[0m… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense (\u001b[38;5;33mDense\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m5\u001b[0m, \u001b[38;5;34m17\u001b[0m)     │      \u001b[38;5;34m8,721\u001b[0m │ concatenate[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m] │\n",
       "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,264,401</span> (4.82 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m1,264,401\u001b[0m (4.82 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,264,401</span> (4.82 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m1,264,401\u001b[0m (4.82 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from tensorflow.keras.layers import AdditiveAttention, Concatenate, Dense, Embedding, Input, LSTM\n",
    "from tensorflow.keras.models import Model\n",
    " \n",
    "# Encoder\n",
    "encoder_inputs = Input(shape=(max_input_length,))\n",
    "encoder_embedding = Embedding(input_vocab_size, 256)(encoder_inputs)\n",
    "encoder_lstm = LSTM(256, return_sequences=True, return_state=True)\n",
    "encoder_outputs, state_h, state_c = encoder_lstm(encoder_embedding)\n",
    "encoder_states = [state_h, state_c]\n",
    " \n",
    "# Decoder\n",
    "decoder_inputs = Input(shape=(max_output_length - 1,))\n",
    "decoder_embedding = Embedding(output_vocab_size, 256)(decoder_inputs)\n",
    "decoder_lstm = LSTM(256, return_sequences=True, return_state=True)\n",
    "decoder_outputs, _, _ = decoder_lstm(decoder_embedding, initial_state=encoder_states)\n",
    " \n",
    "# Attention: decoder attends to encoder outputs\n",
    "self_attention = SelfAttention()\n",
    "attention_output = self_attention(\n",
    "    [decoder_outputs, encoder_outputs, encoder_outputs]\n",
    ")\n",
    "\n",
    " \n",
    "# Combine decoder outputs with attention context\n",
    "decoder_concat = Concatenate(axis=-1)([decoder_outputs, attention_output])\n",
    " \n",
    "# Final Dense layer\n",
    "decoder_dense = Dense(output_vocab_size, activation='softmax')\n",
    "decoder_outputs = decoder_dense(decoder_concat)\n",
    " \n",
    "# Full Model\n",
    "model = Model([encoder_inputs, decoder_inputs], decoder_outputs)\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    " \n",
    "# Summary\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 4: Training the Model\n",
    "Uses categorical_crossentropy as the loss function since output words are one-hot encoded.\n",
    "Trains using Adam optimizer for 100 epochs.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5s/step - accuracy: 0.0400 - loss: 2.8337\n",
      "Epoch 2/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 97ms/step - accuracy: 0.3600 - loss: 2.7992\n",
      "Epoch 3/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 96ms/step - accuracy: 0.3200 - loss: 2.7621\n",
      "Epoch 4/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 94ms/step - accuracy: 0.3200 - loss: 2.7179\n",
      "Epoch 5/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 112ms/step - accuracy: 0.3200 - loss: 2.6616\n",
      "Epoch 6/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 96ms/step - accuracy: 0.3200 - loss: 2.5882\n",
      "Epoch 7/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 100ms/step - accuracy: 0.2800 - loss: 2.4922\n",
      "Epoch 8/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 100ms/step - accuracy: 0.2800 - loss: 2.3710\n",
      "Epoch 9/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 118ms/step - accuracy: 0.2800 - loss: 2.2350\n",
      "Epoch 10/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 107ms/step - accuracy: 0.2800 - loss: 2.1284\n",
      "Epoch 11/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 100ms/step - accuracy: 0.2400 - loss: 2.1015\n",
      "Epoch 12/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 101ms/step - accuracy: 0.2800 - loss: 2.0760\n",
      "Epoch 13/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 177ms/step - accuracy: 0.2800 - loss: 1.9962\n",
      "Epoch 14/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 98ms/step - accuracy: 0.3200 - loss: 1.9086\n",
      "Epoch 15/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 91ms/step - accuracy: 0.4400 - loss: 1.8468\n",
      "Epoch 16/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 96ms/step - accuracy: 0.4400 - loss: 1.7895\n",
      "Epoch 17/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 96ms/step - accuracy: 0.4800 - loss: 1.7189\n",
      "Epoch 18/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 94ms/step - accuracy: 0.5600 - loss: 1.6399\n",
      "Epoch 19/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 100ms/step - accuracy: 0.6000 - loss: 1.5596\n",
      "Epoch 20/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 89ms/step - accuracy: 0.6400 - loss: 1.4811\n",
      "Epoch 21/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 138ms/step - accuracy: 0.6000 - loss: 1.4049\n",
      "Epoch 22/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 123ms/step - accuracy: 0.6000 - loss: 1.3300\n",
      "Epoch 23/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 94ms/step - accuracy: 0.6000 - loss: 1.2542\n",
      "Epoch 24/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 96ms/step - accuracy: 0.5600 - loss: 1.1751\n",
      "Epoch 25/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 107ms/step - accuracy: 0.6000 - loss: 1.0924\n",
      "Epoch 26/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 123ms/step - accuracy: 0.7200 - loss: 1.0092\n",
      "Epoch 27/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 113ms/step - accuracy: 0.7200 - loss: 0.9294\n",
      "Epoch 28/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 108ms/step - accuracy: 0.7600 - loss: 0.8571\n",
      "Epoch 29/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 221ms/step - accuracy: 0.8800 - loss: 0.7955\n",
      "Epoch 30/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 98ms/step - accuracy: 0.9200 - loss: 0.7348\n",
      "Epoch 31/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 112ms/step - accuracy: 0.9600 - loss: 0.6725\n",
      "Epoch 32/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 125ms/step - accuracy: 0.9200 - loss: 0.6130\n",
      "Epoch 33/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 106ms/step - accuracy: 0.9200 - loss: 0.5607\n",
      "Epoch 34/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 100ms/step - accuracy: 0.9600 - loss: 0.5086\n",
      "Epoch 35/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 108ms/step - accuracy: 0.9600 - loss: 0.4548\n",
      "Epoch 36/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 101ms/step - accuracy: 1.0000 - loss: 0.4063\n",
      "Epoch 37/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 103ms/step - accuracy: 1.0000 - loss: 0.3708\n",
      "Epoch 38/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 101ms/step - accuracy: 1.0000 - loss: 0.3372\n",
      "Epoch 39/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 121ms/step - accuracy: 1.0000 - loss: 0.3005\n",
      "Epoch 40/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 184ms/step - accuracy: 1.0000 - loss: 0.2699\n",
      "Epoch 41/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 128ms/step - accuracy: 1.0000 - loss: 0.2411\n",
      "Epoch 42/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 98ms/step - accuracy: 1.0000 - loss: 0.2138\n",
      "Epoch 43/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 103ms/step - accuracy: 1.0000 - loss: 0.1929\n",
      "Epoch 44/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 104ms/step - accuracy: 1.0000 - loss: 0.1761\n",
      "Epoch 45/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 102ms/step - accuracy: 1.0000 - loss: 0.1610\n",
      "Epoch 46/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 121ms/step - accuracy: 1.0000 - loss: 0.1442\n",
      "Epoch 47/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 129ms/step - accuracy: 1.0000 - loss: 0.1284\n",
      "Epoch 48/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 108ms/step - accuracy: 1.0000 - loss: 0.1171\n",
      "Epoch 49/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 106ms/step - accuracy: 1.0000 - loss: 0.1067\n",
      "Epoch 50/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 115ms/step - accuracy: 1.0000 - loss: 0.0955\n",
      "Epoch 51/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 166ms/step - accuracy: 1.0000 - loss: 0.0857\n",
      "Epoch 52/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 146ms/step - accuracy: 1.0000 - loss: 0.0763\n",
      "Epoch 53/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 103ms/step - accuracy: 1.0000 - loss: 0.0699\n",
      "Epoch 54/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 151ms/step - accuracy: 1.0000 - loss: 0.0628\n",
      "Epoch 55/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 171ms/step - accuracy: 1.0000 - loss: 0.0576\n",
      "Epoch 56/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 145ms/step - accuracy: 1.0000 - loss: 0.0519\n",
      "Epoch 57/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 165ms/step - accuracy: 1.0000 - loss: 0.0478\n",
      "Epoch 58/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 159ms/step - accuracy: 1.0000 - loss: 0.0429\n",
      "Epoch 59/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 139ms/step - accuracy: 1.0000 - loss: 0.0398\n",
      "Epoch 60/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 187ms/step - accuracy: 1.0000 - loss: 0.0363\n",
      "Epoch 61/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 190ms/step - accuracy: 1.0000 - loss: 0.0339\n",
      "Epoch 62/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 131ms/step - accuracy: 1.0000 - loss: 0.0311\n",
      "Epoch 63/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 121ms/step - accuracy: 1.0000 - loss: 0.0287\n",
      "Epoch 64/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 132ms/step - accuracy: 1.0000 - loss: 0.0265\n",
      "Epoch 65/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 98ms/step - accuracy: 1.0000 - loss: 0.0248\n",
      "Epoch 66/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 121ms/step - accuracy: 1.0000 - loss: 0.0231\n",
      "Epoch 67/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 126ms/step - accuracy: 1.0000 - loss: 0.0217\n",
      "Epoch 68/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 113ms/step - accuracy: 1.0000 - loss: 0.0202\n",
      "Epoch 69/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 96ms/step - accuracy: 1.0000 - loss: 0.0189\n",
      "Epoch 70/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 164ms/step - accuracy: 1.0000 - loss: 0.0177\n",
      "Epoch 71/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 131ms/step - accuracy: 1.0000 - loss: 0.0166\n",
      "Epoch 72/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 128ms/step - accuracy: 1.0000 - loss: 0.0158\n",
      "Epoch 73/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 113ms/step - accuracy: 1.0000 - loss: 0.0150\n",
      "Epoch 74/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 132ms/step - accuracy: 1.0000 - loss: 0.0143\n",
      "Epoch 75/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 116ms/step - accuracy: 1.0000 - loss: 0.0135\n",
      "Epoch 76/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 111ms/step - accuracy: 1.0000 - loss: 0.0129\n",
      "Epoch 77/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 215ms/step - accuracy: 1.0000 - loss: 0.0122\n",
      "Epoch 78/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 124ms/step - accuracy: 1.0000 - loss: 0.0117\n",
      "Epoch 79/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 123ms/step - accuracy: 1.0000 - loss: 0.0112\n",
      "Epoch 80/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 92ms/step - accuracy: 1.0000 - loss: 0.0107\n",
      "Epoch 81/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 128ms/step - accuracy: 1.0000 - loss: 0.0103\n",
      "Epoch 82/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 124ms/step - accuracy: 1.0000 - loss: 0.0099\n",
      "Epoch 83/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 115ms/step - accuracy: 1.0000 - loss: 0.0095\n",
      "Epoch 84/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 136ms/step - accuracy: 1.0000 - loss: 0.0091\n",
      "Epoch 85/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 209ms/step - accuracy: 1.0000 - loss: 0.0088\n",
      "Epoch 86/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 122ms/step - accuracy: 1.0000 - loss: 0.0085\n",
      "Epoch 87/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 100ms/step - accuracy: 1.0000 - loss: 0.0082\n",
      "Epoch 88/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 140ms/step - accuracy: 1.0000 - loss: 0.0080\n",
      "Epoch 89/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 109ms/step - accuracy: 1.0000 - loss: 0.0077\n",
      "Epoch 90/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 121ms/step - accuracy: 1.0000 - loss: 0.0075\n",
      "Epoch 91/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 131ms/step - accuracy: 1.0000 - loss: 0.0072\n",
      "Epoch 92/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 157ms/step - accuracy: 1.0000 - loss: 0.0070\n",
      "Epoch 93/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 192ms/step - accuracy: 1.0000 - loss: 0.0068\n",
      "Epoch 94/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 114ms/step - accuracy: 1.0000 - loss: 0.0066\n",
      "Epoch 95/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 134ms/step - accuracy: 1.0000 - loss: 0.0065\n",
      "Epoch 96/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 122ms/step - accuracy: 1.0000 - loss: 0.0063\n",
      "Epoch 97/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 141ms/step - accuracy: 1.0000 - loss: 0.0061\n",
      "Epoch 98/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 118ms/step - accuracy: 1.0000 - loss: 0.0060\n",
      "Epoch 99/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 125ms/step - accuracy: 1.0000 - loss: 0.0058\n",
      "Epoch 100/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 148ms/step - accuracy: 1.0000 - loss: 0.0057\n"
     ]
    }
   ],
   "source": [
    "# Step 6: Train the Model\n",
    "history_glorot_adam = model.fit([input_sequences, decoder_input_data], decoder_output_data, epochs=100, batch_size=16)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 5: Plotting the training loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plotting training loss\n",
    "import matplotlib.pyplot as plt\n",
    "plt.plot(history_glorot_adam.history['loss'])\n",
    "plt.title('Training Loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Awesome, now you have succesfully trained a transformers model.\n",
    "### Now let's try some practice excercises\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Practice excercise 1\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this practice exercise, let's train the model using \"he_uniform\" initializer instead of \"glorot_uniform\". Then, compare the training loss between model using \"glorot_uniform\" vs \"he_uniform\" initializers by plotting them using matplotlib\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_2\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"functional_2\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)        </span>┃<span style=\"font-weight: bold\"> Output Shape      </span>┃<span style=\"font-weight: bold\">    Param # </span>┃<span style=\"font-weight: bold\"> Connected to      </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
       "│ input_layer_4       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>)         │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ input_layer_5       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>)         │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ embedding_4         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)    │      <span style=\"color: #00af00; text-decoration-color: #00af00\">4,096</span> │ input_layer_4[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)         │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ embedding_5         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)    │      <span style=\"color: #00af00; text-decoration-color: #00af00\">4,352</span> │ input_layer_5[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)         │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ lstm_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)       │ [(<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>),  │    <span style=\"color: #00af00; text-decoration-color: #00af00\">525,312</span> │ embedding_4[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>] │\n",
       "│                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>),      │            │                   │\n",
       "│                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)]      │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ lstm_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)       │ [(<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>),  │    <span style=\"color: #00af00; text-decoration-color: #00af00\">525,312</span> │ embedding_5[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>… │\n",
       "│                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>),      │            │ lstm_4[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>],     │\n",
       "│                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)]      │            │ lstm_4[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>]      │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ self_attention_2    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)    │    <span style=\"color: #00af00; text-decoration-color: #00af00\">196,608</span> │ lstm_5[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],     │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">SelfAttention</span>)     │                   │            │ lstm_4[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],     │\n",
       "│                     │                   │            │ lstm_4[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]      │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ concatenate_2       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ lstm_5[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],     │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Concatenate</span>)       │                   │            │ self_attention_2… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">17</span>)     │      <span style=\"color: #00af00; text-decoration-color: #00af00\">8,721</span> │ concatenate_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
       "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m   Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to     \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
       "│ input_layer_4       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m5\u001b[0m)         │          \u001b[38;5;34m0\u001b[0m │ -                 │\n",
       "│ (\u001b[38;5;33mInputLayer\u001b[0m)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ input_layer_5       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m5\u001b[0m)         │          \u001b[38;5;34m0\u001b[0m │ -                 │\n",
       "│ (\u001b[38;5;33mInputLayer\u001b[0m)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ embedding_4         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m5\u001b[0m, \u001b[38;5;34m256\u001b[0m)    │      \u001b[38;5;34m4,096\u001b[0m │ input_layer_4[\u001b[38;5;34m0\u001b[0m]… │\n",
       "│ (\u001b[38;5;33mEmbedding\u001b[0m)         │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ embedding_5         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m5\u001b[0m, \u001b[38;5;34m256\u001b[0m)    │      \u001b[38;5;34m4,352\u001b[0m │ input_layer_5[\u001b[38;5;34m0\u001b[0m]… │\n",
       "│ (\u001b[38;5;33mEmbedding\u001b[0m)         │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ lstm_4 (\u001b[38;5;33mLSTM\u001b[0m)       │ [(\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m5\u001b[0m, \u001b[38;5;34m256\u001b[0m),  │    \u001b[38;5;34m525,312\u001b[0m │ embedding_4[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m] │\n",
       "│                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m),      │            │                   │\n",
       "│                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)]      │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ lstm_5 (\u001b[38;5;33mLSTM\u001b[0m)       │ [(\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m5\u001b[0m, \u001b[38;5;34m256\u001b[0m),  │    \u001b[38;5;34m525,312\u001b[0m │ embedding_5[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m… │\n",
       "│                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m),      │            │ lstm_4[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m1\u001b[0m],     │\n",
       "│                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)]      │            │ lstm_4[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m2\u001b[0m]      │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ self_attention_2    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m5\u001b[0m, \u001b[38;5;34m256\u001b[0m)    │    \u001b[38;5;34m196,608\u001b[0m │ lstm_5[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],     │\n",
       "│ (\u001b[38;5;33mSelfAttention\u001b[0m)     │                   │            │ lstm_4[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],     │\n",
       "│                     │                   │            │ lstm_4[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]      │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ concatenate_2       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m5\u001b[0m, \u001b[38;5;34m512\u001b[0m)    │          \u001b[38;5;34m0\u001b[0m │ lstm_5[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],     │\n",
       "│ (\u001b[38;5;33mConcatenate\u001b[0m)       │                   │            │ self_attention_2… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_2 (\u001b[38;5;33mDense\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m5\u001b[0m, \u001b[38;5;34m17\u001b[0m)     │      \u001b[38;5;34m8,721\u001b[0m │ concatenate_2[\u001b[38;5;34m0\u001b[0m]… │\n",
       "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,264,401</span> (4.82 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m1,264,401\u001b[0m (4.82 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,264,401</span> (4.82 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m1,264,401\u001b[0m (4.82 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5s/step - accuracy: 0.0400 - loss: 2.8328\n",
      "Epoch 2/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 108ms/step - accuracy: 0.3600 - loss: 2.7922\n",
      "Epoch 3/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 105ms/step - accuracy: 0.3600 - loss: 2.7484\n",
      "Epoch 4/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 96ms/step - accuracy: 0.3200 - loss: 2.6964\n",
      "Epoch 5/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 113ms/step - accuracy: 0.3200 - loss: 2.6310\n",
      "Epoch 6/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 150ms/step - accuracy: 0.3200 - loss: 2.5468\n",
      "Epoch 7/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 170ms/step - accuracy: 0.3200 - loss: 2.4396\n",
      "Epoch 8/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 152ms/step - accuracy: 0.2800 - loss: 2.3117\n",
      "Epoch 9/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 159ms/step - accuracy: 0.2800 - loss: 2.1875\n",
      "Epoch 10/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 161ms/step - accuracy: 0.2800 - loss: 2.1213\n",
      "Epoch 11/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 112ms/step - accuracy: 0.2800 - loss: 2.1057\n",
      "Epoch 12/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 130ms/step - accuracy: 0.3200 - loss: 2.0488\n",
      "Epoch 13/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 129ms/step - accuracy: 0.3200 - loss: 1.9606\n",
      "Epoch 14/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 108ms/step - accuracy: 0.4400 - loss: 1.8904\n",
      "Epoch 15/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 121ms/step - accuracy: 0.4400 - loss: 1.8348\n",
      "Epoch 16/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 107ms/step - accuracy: 0.4400 - loss: 1.7680\n",
      "Epoch 17/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 117ms/step - accuracy: 0.5200 - loss: 1.6918\n",
      "Epoch 18/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 140ms/step - accuracy: 0.5600 - loss: 1.6152\n",
      "Epoch 19/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 127ms/step - accuracy: 0.6000 - loss: 1.5424\n",
      "Epoch 20/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 153ms/step - accuracy: 0.6000 - loss: 1.4727\n",
      "Epoch 21/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 124ms/step - accuracy: 0.5600 - loss: 1.4034\n",
      "Epoch 22/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 92ms/step - accuracy: 0.5600 - loss: 1.3300\n",
      "Epoch 23/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 136ms/step - accuracy: 0.5600 - loss: 1.2491\n",
      "Epoch 24/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 209ms/step - accuracy: 0.6000 - loss: 1.1606\n",
      "Epoch 25/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 102ms/step - accuracy: 0.6400 - loss: 1.0693\n",
      "Epoch 26/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 102ms/step - accuracy: 0.7200 - loss: 0.9810\n",
      "Epoch 27/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 116ms/step - accuracy: 0.7200 - loss: 0.8988\n",
      "Epoch 28/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 113ms/step - accuracy: 0.8400 - loss: 0.8233\n",
      "Epoch 29/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 98ms/step - accuracy: 0.8400 - loss: 0.7531\n",
      "Epoch 30/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 114ms/step - accuracy: 0.8400 - loss: 0.6845\n",
      "Epoch 31/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 106ms/step - accuracy: 0.9200 - loss: 0.6204\n",
      "Epoch 32/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 127ms/step - accuracy: 0.9600 - loss: 0.5646\n",
      "Epoch 33/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 109ms/step - accuracy: 0.9600 - loss: 0.5128\n",
      "Epoch 34/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 108ms/step - accuracy: 0.9600 - loss: 0.4603\n",
      "Epoch 35/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 122ms/step - accuracy: 1.0000 - loss: 0.4100\n",
      "Epoch 36/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 115ms/step - accuracy: 1.0000 - loss: 0.3684\n",
      "Epoch 37/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 117ms/step - accuracy: 1.0000 - loss: 0.3347\n",
      "Epoch 38/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 184ms/step - accuracy: 1.0000 - loss: 0.3013\n",
      "Epoch 39/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 225ms/step - accuracy: 1.0000 - loss: 0.2641\n",
      "Epoch 40/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 117ms/step - accuracy: 1.0000 - loss: 0.2315\n",
      "Epoch 41/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 119ms/step - accuracy: 1.0000 - loss: 0.2047\n",
      "Epoch 42/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 114ms/step - accuracy: 1.0000 - loss: 0.1839\n",
      "Epoch 43/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 97ms/step - accuracy: 1.0000 - loss: 0.1665\n",
      "Epoch 44/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 123ms/step - accuracy: 1.0000 - loss: 0.1510\n",
      "Epoch 45/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 158ms/step - accuracy: 1.0000 - loss: 0.1324\n",
      "Epoch 46/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 139ms/step - accuracy: 1.0000 - loss: 0.1191\n",
      "Epoch 47/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 156ms/step - accuracy: 1.0000 - loss: 0.1079\n",
      "Epoch 48/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 148ms/step - accuracy: 1.0000 - loss: 0.0971\n",
      "Epoch 49/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 189ms/step - accuracy: 1.0000 - loss: 0.0909\n",
      "Epoch 50/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 155ms/step - accuracy: 1.0000 - loss: 0.0813\n",
      "Epoch 51/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 156ms/step - accuracy: 1.0000 - loss: 0.0731\n",
      "Epoch 52/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 228ms/step - accuracy: 1.0000 - loss: 0.0672\n",
      "Epoch 53/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 129ms/step - accuracy: 1.0000 - loss: 0.0589\n",
      "Epoch 54/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 110ms/step - accuracy: 1.0000 - loss: 0.0543\n",
      "Epoch 55/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 122ms/step - accuracy: 1.0000 - loss: 0.0482\n",
      "Epoch 56/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 111ms/step - accuracy: 1.0000 - loss: 0.0452\n",
      "Epoch 57/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 100ms/step - accuracy: 1.0000 - loss: 0.0403\n",
      "Epoch 58/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 110ms/step - accuracy: 1.0000 - loss: 0.0372\n",
      "Epoch 59/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 132ms/step - accuracy: 1.0000 - loss: 0.0334\n",
      "Epoch 60/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 109ms/step - accuracy: 1.0000 - loss: 0.0312\n",
      "Epoch 61/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 128ms/step - accuracy: 1.0000 - loss: 0.0283\n",
      "Epoch 62/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 133ms/step - accuracy: 1.0000 - loss: 0.0266\n",
      "Epoch 63/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 218ms/step - accuracy: 1.0000 - loss: 0.0241\n",
      "Epoch 64/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 129ms/step - accuracy: 1.0000 - loss: 0.0228\n",
      "Epoch 65/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 125ms/step - accuracy: 1.0000 - loss: 0.0211\n",
      "Epoch 66/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 134ms/step - accuracy: 1.0000 - loss: 0.0197\n",
      "Epoch 67/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 120ms/step - accuracy: 1.0000 - loss: 0.0184\n",
      "Epoch 68/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 121ms/step - accuracy: 1.0000 - loss: 0.0170\n",
      "Epoch 69/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 119ms/step - accuracy: 1.0000 - loss: 0.0162\n",
      "Epoch 70/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 135ms/step - accuracy: 1.0000 - loss: 0.0151\n",
      "Epoch 71/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 127ms/step - accuracy: 1.0000 - loss: 0.0143\n",
      "Epoch 72/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 211ms/step - accuracy: 1.0000 - loss: 0.0135\n",
      "Epoch 73/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 165ms/step - accuracy: 1.0000 - loss: 0.0127\n",
      "Epoch 74/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 141ms/step - accuracy: 1.0000 - loss: 0.0122\n",
      "Epoch 75/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 123ms/step - accuracy: 1.0000 - loss: 0.0115\n",
      "Epoch 76/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 112ms/step - accuracy: 1.0000 - loss: 0.0110\n",
      "Epoch 77/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 130ms/step - accuracy: 1.0000 - loss: 0.0105\n",
      "Epoch 78/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 115ms/step - accuracy: 1.0000 - loss: 0.0099\n",
      "Epoch 79/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 121ms/step - accuracy: 1.0000 - loss: 0.0096\n",
      "Epoch 80/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 125ms/step - accuracy: 1.0000 - loss: 0.0091\n",
      "Epoch 81/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 119ms/step - accuracy: 1.0000 - loss: 0.0088\n",
      "Epoch 82/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 215ms/step - accuracy: 1.0000 - loss: 0.0085\n",
      "Epoch 83/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 133ms/step - accuracy: 1.0000 - loss: 0.0081\n",
      "Epoch 84/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 142ms/step - accuracy: 1.0000 - loss: 0.0079\n",
      "Epoch 85/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 124ms/step - accuracy: 1.0000 - loss: 0.0076\n",
      "Epoch 86/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 128ms/step - accuracy: 1.0000 - loss: 0.0073\n",
      "Epoch 87/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 133ms/step - accuracy: 1.0000 - loss: 0.0071\n",
      "Epoch 88/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 127ms/step - accuracy: 1.0000 - loss: 0.0069\n",
      "Epoch 89/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 207ms/step - accuracy: 1.0000 - loss: 0.0066\n",
      "Epoch 90/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 213ms/step - accuracy: 1.0000 - loss: 0.0064\n",
      "Epoch 91/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 113ms/step - accuracy: 1.0000 - loss: 0.0063\n",
      "Epoch 92/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 124ms/step - accuracy: 1.0000 - loss: 0.0061\n",
      "Epoch 93/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 133ms/step - accuracy: 1.0000 - loss: 0.0059\n",
      "Epoch 94/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 110ms/step - accuracy: 1.0000 - loss: 0.0057\n",
      "Epoch 95/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 127ms/step - accuracy: 1.0000 - loss: 0.0056\n",
      "Epoch 96/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 123ms/step - accuracy: 1.0000 - loss: 0.0054\n",
      "Epoch 97/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 115ms/step - accuracy: 1.0000 - loss: 0.0053\n",
      "Epoch 98/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 154ms/step - accuracy: 1.0000 - loss: 0.0052\n",
      "Epoch 99/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 211ms/step - accuracy: 1.0000 - loss: 0.0051\n",
      "Epoch 100/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 130ms/step - accuracy: 1.0000 - loss: 0.0049\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "## Write your answer here\n",
    "from tensorflow.keras.layers import Layer\n",
    "from tensorflow.keras import backend as K\n",
    "\n",
    "class SelfAttention(Layer):\n",
    "    def __init__(self, **kwargs):\n",
    "        super(SelfAttention, self).__init__(**kwargs)\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        # input_shape is a list: [q_shape, k_shape, v_shape]\n",
    "        feature_dim = input_shape[0][-1]\n",
    "\n",
    "        self.Wq = self.add_weight(\n",
    "            shape=(feature_dim, feature_dim),\n",
    "            initializer='he_uniform',\n",
    "            trainable=True,\n",
    "            name='Wq'\n",
    "        )\n",
    "\n",
    "        self.Wk = self.add_weight(\n",
    "            shape=(feature_dim, feature_dim),\n",
    "            initializer='he_uniform',\n",
    "            trainable=True,\n",
    "            name='Wk'\n",
    "        )\n",
    "\n",
    "        self.Wv = self.add_weight(\n",
    "            shape=(feature_dim, feature_dim),\n",
    "            initializer='he_uniform',\n",
    "            trainable=True,\n",
    "            name='Wv'\n",
    "        )\n",
    "\n",
    "        super(SelfAttention, self).build(input_shape)\n",
    "\n",
    "    def call(self, inputs):\n",
    "        # Expect list: [query, key, value]\n",
    "        q, k, v = inputs\n",
    "\n",
    "        q = K.dot(q, self.Wq)\n",
    "        k = K.dot(k, self.Wk)\n",
    "        v = K.dot(v, self.Wv)\n",
    "\n",
    "        # Scaled dot-product attention\n",
    "        scores = K.batch_dot(q, k, axes=[2, 2])\n",
    "        dk = K.cast(K.shape(k)[-1], dtype=K.floatx())\n",
    "        scores = scores / K.sqrt(dk)\n",
    "\n",
    "        attention_weights = K.softmax(scores, axis=-1)\n",
    "        output = K.batch_dot(attention_weights, v)\n",
    "\n",
    "        return output\n",
    "from tensorflow.keras.layers import AdditiveAttention, Concatenate, Dense, Embedding, Input, LSTM\n",
    "from tensorflow.keras.models import Model\n",
    " \n",
    "# Encoder\n",
    "encoder_inputs = Input(shape=(max_input_length,))\n",
    "encoder_embedding = Embedding(input_vocab_size, 256)(encoder_inputs)\n",
    "encoder_lstm = LSTM(256, return_sequences=True, return_state=True)\n",
    "encoder_outputs, state_h, state_c = encoder_lstm(encoder_embedding)\n",
    "encoder_states = [state_h, state_c]\n",
    " \n",
    "# Decoder\n",
    "decoder_inputs = Input(shape=(max_output_length - 1,))\n",
    "decoder_embedding = Embedding(output_vocab_size, 256)(decoder_inputs)\n",
    "decoder_lstm = LSTM(256, return_sequences=True, return_state=True)\n",
    "decoder_outputs, _, _ = decoder_lstm(decoder_embedding, initial_state=encoder_states)\n",
    " \n",
    "# Attention: decoder attends to encoder outputs\n",
    "self_attention = SelfAttention()\n",
    "attention_output = self_attention(\n",
    "    [decoder_outputs, encoder_outputs, encoder_outputs]\n",
    ")\n",
    "\n",
    " \n",
    "# Combine decoder outputs with attention context\n",
    "decoder_concat = Concatenate(axis=-1)([decoder_outputs, attention_output])\n",
    " \n",
    "# Final Dense layer\n",
    "decoder_dense = Dense(output_vocab_size, activation='softmax')\n",
    "decoder_outputs = decoder_dense(decoder_concat)\n",
    " \n",
    "# Full Model\n",
    "model = Model([encoder_inputs, decoder_inputs], decoder_outputs)\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    " \n",
    "# Summary\n",
    "model.summary()\n",
    "\n",
    "\n",
    "# Step 6: Train the Model\n",
    "history_glorot_adam = model.fit([input_sequences, decoder_input_data], decoder_output_data, epochs=100, batch_size=16)\n",
    "\n",
    "# Plotting training loss\n",
    "import matplotlib.pyplot as plt\n",
    "plt.plot(history_glorot_adam.history['loss'])\n",
    "plt.title('Training Loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Practice excercise 2\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this practice exercise, try to use adaptive gradient optimizer instead of adam. Then, plot and compare the results between adam and adaptive gradient optimizers\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_7\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"functional_7\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)        </span>┃<span style=\"font-weight: bold\"> Output Shape      </span>┃<span style=\"font-weight: bold\">    Param # </span>┃<span style=\"font-weight: bold\"> Connected to      </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
       "│ input_layer_14      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>)         │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ input_layer_15      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>)         │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ embedding_14        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)    │      <span style=\"color: #00af00; text-decoration-color: #00af00\">4,096</span> │ input_layer_14[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)         │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ embedding_15        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)    │      <span style=\"color: #00af00; text-decoration-color: #00af00\">4,352</span> │ input_layer_15[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)         │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ lstm_14 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)      │ [(<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>),  │    <span style=\"color: #00af00; text-decoration-color: #00af00\">525,312</span> │ embedding_14[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n",
       "│                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>),      │            │                   │\n",
       "│                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)]      │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ lstm_15 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)      │ [(<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>),  │    <span style=\"color: #00af00; text-decoration-color: #00af00\">525,312</span> │ embedding_15[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n",
       "│                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>),      │            │ lstm_14[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>],    │\n",
       "│                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)]      │            │ lstm_14[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>]     │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ self_attention_7    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)    │    <span style=\"color: #00af00; text-decoration-color: #00af00\">196,608</span> │ lstm_15[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],    │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">SelfAttention</span>)     │                   │            │ lstm_14[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],    │\n",
       "│                     │                   │            │ lstm_14[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ concatenate_7       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ lstm_15[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],    │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Concatenate</span>)       │                   │            │ self_attention_7… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_7 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">17</span>)     │      <span style=\"color: #00af00; text-decoration-color: #00af00\">8,721</span> │ concatenate_7[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
       "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m   Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to     \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
       "│ input_layer_14      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m5\u001b[0m)         │          \u001b[38;5;34m0\u001b[0m │ -                 │\n",
       "│ (\u001b[38;5;33mInputLayer\u001b[0m)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ input_layer_15      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m5\u001b[0m)         │          \u001b[38;5;34m0\u001b[0m │ -                 │\n",
       "│ (\u001b[38;5;33mInputLayer\u001b[0m)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ embedding_14        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m5\u001b[0m, \u001b[38;5;34m256\u001b[0m)    │      \u001b[38;5;34m4,096\u001b[0m │ input_layer_14[\u001b[38;5;34m0\u001b[0m… │\n",
       "│ (\u001b[38;5;33mEmbedding\u001b[0m)         │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ embedding_15        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m5\u001b[0m, \u001b[38;5;34m256\u001b[0m)    │      \u001b[38;5;34m4,352\u001b[0m │ input_layer_15[\u001b[38;5;34m0\u001b[0m… │\n",
       "│ (\u001b[38;5;33mEmbedding\u001b[0m)         │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ lstm_14 (\u001b[38;5;33mLSTM\u001b[0m)      │ [(\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m5\u001b[0m, \u001b[38;5;34m256\u001b[0m),  │    \u001b[38;5;34m525,312\u001b[0m │ embedding_14[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m…\u001b[0m │\n",
       "│                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m),      │            │                   │\n",
       "│                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)]      │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ lstm_15 (\u001b[38;5;33mLSTM\u001b[0m)      │ [(\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m5\u001b[0m, \u001b[38;5;34m256\u001b[0m),  │    \u001b[38;5;34m525,312\u001b[0m │ embedding_15[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m…\u001b[0m │\n",
       "│                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m),      │            │ lstm_14[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m1\u001b[0m],    │\n",
       "│                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)]      │            │ lstm_14[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m2\u001b[0m]     │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ self_attention_7    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m5\u001b[0m, \u001b[38;5;34m256\u001b[0m)    │    \u001b[38;5;34m196,608\u001b[0m │ lstm_15[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],    │\n",
       "│ (\u001b[38;5;33mSelfAttention\u001b[0m)     │                   │            │ lstm_14[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],    │\n",
       "│                     │                   │            │ lstm_14[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]     │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ concatenate_7       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m5\u001b[0m, \u001b[38;5;34m512\u001b[0m)    │          \u001b[38;5;34m0\u001b[0m │ lstm_15[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],    │\n",
       "│ (\u001b[38;5;33mConcatenate\u001b[0m)       │                   │            │ self_attention_7… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_7 (\u001b[38;5;33mDense\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m5\u001b[0m, \u001b[38;5;34m17\u001b[0m)     │      \u001b[38;5;34m8,721\u001b[0m │ concatenate_7[\u001b[38;5;34m0\u001b[0m]… │\n",
       "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,264,401</span> (4.82 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m1,264,401\u001b[0m (4.82 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,264,401</span> (4.82 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m1,264,401\u001b[0m (4.82 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5s/step - accuracy: 0.0800 - loss: 2.8323\n",
      "Epoch 2/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 122ms/step - accuracy: 0.0800 - loss: 2.8318\n",
      "Epoch 3/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 113ms/step - accuracy: 0.0800 - loss: 2.8314\n",
      "Epoch 4/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 128ms/step - accuracy: 0.0800 - loss: 2.8310\n",
      "Epoch 5/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 145ms/step - accuracy: 0.0800 - loss: 2.8307\n",
      "Epoch 6/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 120ms/step - accuracy: 0.0800 - loss: 2.8303\n",
      "Epoch 7/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 110ms/step - accuracy: 0.0800 - loss: 2.8299\n",
      "Epoch 8/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 82ms/step - accuracy: 0.0800 - loss: 2.8295\n",
      "Epoch 9/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 115ms/step - accuracy: 0.0800 - loss: 2.8292\n",
      "Epoch 10/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 88ms/step - accuracy: 0.0800 - loss: 2.8288\n",
      "Epoch 11/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 108ms/step - accuracy: 0.1200 - loss: 2.8285\n",
      "Epoch 12/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 110ms/step - accuracy: 0.1200 - loss: 2.8281\n",
      "Epoch 13/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 91ms/step - accuracy: 0.1600 - loss: 2.8278\n",
      "Epoch 14/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 100ms/step - accuracy: 0.1600 - loss: 2.8274\n",
      "Epoch 15/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 138ms/step - accuracy: 0.1600 - loss: 2.8271\n",
      "Epoch 16/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 135ms/step - accuracy: 0.2000 - loss: 2.8268\n",
      "Epoch 17/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 92ms/step - accuracy: 0.2000 - loss: 2.8264\n",
      "Epoch 18/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 106ms/step - accuracy: 0.2000 - loss: 2.8261\n",
      "Epoch 19/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 97ms/step - accuracy: 0.1600 - loss: 2.8258\n",
      "Epoch 20/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 96ms/step - accuracy: 0.1600 - loss: 2.8254\n",
      "Epoch 21/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 92ms/step - accuracy: 0.1600 - loss: 2.8251\n",
      "Epoch 22/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 114ms/step - accuracy: 0.1600 - loss: 2.8248\n",
      "Epoch 23/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 204ms/step - accuracy: 0.1600 - loss: 2.8245\n",
      "Epoch 24/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 122ms/step - accuracy: 0.1600 - loss: 2.8241\n",
      "Epoch 25/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 103ms/step - accuracy: 0.1600 - loss: 2.8238\n",
      "Epoch 26/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 113ms/step - accuracy: 0.1600 - loss: 2.8235\n",
      "Epoch 27/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 100ms/step - accuracy: 0.1600 - loss: 2.8232\n",
      "Epoch 28/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 105ms/step - accuracy: 0.1600 - loss: 2.8229\n",
      "Epoch 29/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 91ms/step - accuracy: 0.2000 - loss: 2.8226\n",
      "Epoch 30/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 103ms/step - accuracy: 0.2000 - loss: 2.8222\n",
      "Epoch 31/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 100ms/step - accuracy: 0.2400 - loss: 2.8219\n",
      "Epoch 32/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 114ms/step - accuracy: 0.2400 - loss: 2.8216\n",
      "Epoch 33/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 113ms/step - accuracy: 0.2800 - loss: 2.8213\n",
      "Epoch 34/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 178ms/step - accuracy: 0.2800 - loss: 2.8210\n",
      "Epoch 35/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 94ms/step - accuracy: 0.2800 - loss: 2.8207\n",
      "Epoch 36/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 149ms/step - accuracy: 0.2800 - loss: 2.8204\n",
      "Epoch 37/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 105ms/step - accuracy: 0.2800 - loss: 2.8201\n",
      "Epoch 38/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 115ms/step - accuracy: 0.2800 - loss: 2.8198\n",
      "Epoch 39/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 123ms/step - accuracy: 0.2800 - loss: 2.8195\n",
      "Epoch 40/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 293ms/step - accuracy: 0.2800 - loss: 2.8192\n",
      "Epoch 41/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 136ms/step - accuracy: 0.2800 - loss: 2.8189\n",
      "Epoch 42/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 111ms/step - accuracy: 0.2800 - loss: 2.8186\n",
      "Epoch 43/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 98ms/step - accuracy: 0.2800 - loss: 2.8183\n",
      "Epoch 44/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 106ms/step - accuracy: 0.2800 - loss: 2.8180\n",
      "Epoch 45/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 115ms/step - accuracy: 0.2800 - loss: 2.8177\n",
      "Epoch 46/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 98ms/step - accuracy: 0.2800 - loss: 2.8174\n",
      "Epoch 47/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 103ms/step - accuracy: 0.2800 - loss: 2.8171\n",
      "Epoch 48/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 89ms/step - accuracy: 0.2800 - loss: 2.8168\n",
      "Epoch 49/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 123ms/step - accuracy: 0.2800 - loss: 2.8165\n",
      "Epoch 50/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 193ms/step - accuracy: 0.2800 - loss: 2.8162\n",
      "Epoch 51/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 228ms/step - accuracy: 0.2800 - loss: 2.8159\n",
      "Epoch 52/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 144ms/step - accuracy: 0.2800 - loss: 2.8156\n",
      "Epoch 53/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 135ms/step - accuracy: 0.2800 - loss: 2.8153\n",
      "Epoch 54/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 135ms/step - accuracy: 0.2800 - loss: 2.8151\n",
      "Epoch 55/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 134ms/step - accuracy: 0.2400 - loss: 2.8148\n",
      "Epoch 56/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 140ms/step - accuracy: 0.2000 - loss: 2.8145\n",
      "Epoch 57/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 113ms/step - accuracy: 0.2000 - loss: 2.8142\n",
      "Epoch 58/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 105ms/step - accuracy: 0.2000 - loss: 2.8139\n",
      "Epoch 59/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 111ms/step - accuracy: 0.2000 - loss: 2.8136\n",
      "Epoch 60/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 118ms/step - accuracy: 0.2000 - loss: 2.8133\n",
      "Epoch 61/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 117ms/step - accuracy: 0.2000 - loss: 2.8131\n",
      "Epoch 62/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 102ms/step - accuracy: 0.2000 - loss: 2.8128\n",
      "Epoch 63/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 118ms/step - accuracy: 0.2000 - loss: 2.8125\n",
      "Epoch 64/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 198ms/step - accuracy: 0.2000 - loss: 2.8122\n",
      "Epoch 65/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 110ms/step - accuracy: 0.2000 - loss: 2.8119\n",
      "Epoch 66/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 113ms/step - accuracy: 0.2000 - loss: 2.8116\n",
      "Epoch 67/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 99ms/step - accuracy: 0.2000 - loss: 2.8114\n",
      "Epoch 68/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 116ms/step - accuracy: 0.2000 - loss: 2.8111\n",
      "Epoch 69/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 109ms/step - accuracy: 0.2000 - loss: 2.8108\n",
      "Epoch 70/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 109ms/step - accuracy: 0.2000 - loss: 2.8105\n",
      "Epoch 71/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 112ms/step - accuracy: 0.2000 - loss: 2.8102\n",
      "Epoch 72/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 109ms/step - accuracy: 0.2000 - loss: 2.8100\n",
      "Epoch 73/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 131ms/step - accuracy: 0.2000 - loss: 2.8097\n",
      "Epoch 74/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 214ms/step - accuracy: 0.2000 - loss: 2.8094\n",
      "Epoch 75/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 140ms/step - accuracy: 0.2000 - loss: 2.8091\n",
      "Epoch 76/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 108ms/step - accuracy: 0.2000 - loss: 2.8089\n",
      "Epoch 77/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 129ms/step - accuracy: 0.2000 - loss: 2.8086\n",
      "Epoch 78/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 123ms/step - accuracy: 0.2000 - loss: 2.8083\n",
      "Epoch 79/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 98ms/step - accuracy: 0.2000 - loss: 2.8080\n",
      "Epoch 80/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 115ms/step - accuracy: 0.2000 - loss: 2.8078\n",
      "Epoch 81/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 187ms/step - accuracy: 0.2400 - loss: 2.8075\n",
      "Epoch 82/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 205ms/step - accuracy: 0.2400 - loss: 2.8072\n",
      "Epoch 83/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 113ms/step - accuracy: 0.2400 - loss: 2.8069\n",
      "Epoch 84/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 107ms/step - accuracy: 0.2400 - loss: 2.8067\n",
      "Epoch 85/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 118ms/step - accuracy: 0.2400 - loss: 2.8064\n",
      "Epoch 86/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 122ms/step - accuracy: 0.2400 - loss: 2.8061\n",
      "Epoch 87/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 130ms/step - accuracy: 0.2400 - loss: 2.8059\n",
      "Epoch 88/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 135ms/step - accuracy: 0.2400 - loss: 2.8056\n",
      "Epoch 89/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 132ms/step - accuracy: 0.2400 - loss: 2.8053\n",
      "Epoch 90/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 107ms/step - accuracy: 0.2400 - loss: 2.8050\n",
      "Epoch 91/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 126ms/step - accuracy: 0.2400 - loss: 2.8048\n",
      "Epoch 92/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 221ms/step - accuracy: 0.2400 - loss: 2.8045\n",
      "Epoch 93/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 151ms/step - accuracy: 0.2400 - loss: 2.8042\n",
      "Epoch 94/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 134ms/step - accuracy: 0.2400 - loss: 2.8040\n",
      "Epoch 95/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 120ms/step - accuracy: 0.2400 - loss: 2.8037\n",
      "Epoch 96/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 123ms/step - accuracy: 0.2800 - loss: 2.8034\n",
      "Epoch 97/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 152ms/step - accuracy: 0.2800 - loss: 2.8032\n",
      "Epoch 98/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 116ms/step - accuracy: 0.2800 - loss: 2.8029\n",
      "Epoch 99/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 126ms/step - accuracy: 0.2800 - loss: 2.8026\n",
      "Epoch 100/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 109ms/step - accuracy: 0.2800 - loss: 2.8024\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "### Write your answer here\n",
    "## Write your answer here\n",
    "from tensorflow.keras.layers import Layer\n",
    "from tensorflow.keras import backend as K\n",
    "\n",
    "class SelfAttention(Layer):\n",
    "    def __init__(self, **kwargs):\n",
    "        super(SelfAttention, self).__init__(**kwargs)\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        # input_shape is a list: [q_shape, k_shape, v_shape]\n",
    "        feature_dim = input_shape[0][-1]\n",
    "\n",
    "        self.Wq = self.add_weight(\n",
    "            shape=(feature_dim, feature_dim),\n",
    "            initializer='he_uniform',\n",
    "            trainable=True,\n",
    "            name='Wq'\n",
    "        )\n",
    "\n",
    "        self.Wk = self.add_weight(\n",
    "            shape=(feature_dim, feature_dim),\n",
    "            initializer='he_uniform',\n",
    "            trainable=True,\n",
    "            name='Wk'\n",
    "        )\n",
    "\n",
    "        self.Wv = self.add_weight(\n",
    "            shape=(feature_dim, feature_dim),\n",
    "            initializer='he_uniform',\n",
    "            trainable=True,\n",
    "            name='Wv'\n",
    "        )\n",
    "\n",
    "        super(SelfAttention, self).build(input_shape)\n",
    "\n",
    "    def call(self, inputs):\n",
    "        # Expect list: [query, key, value]\n",
    "        q, k, v = inputs\n",
    "\n",
    "        q = K.dot(q, self.Wq)\n",
    "        k = K.dot(k, self.Wk)\n",
    "        v = K.dot(v, self.Wv)\n",
    "\n",
    "        # Scaled dot-product attention\n",
    "        scores = K.batch_dot(q, k, axes=[2, 2])\n",
    "        dk = K.cast(K.shape(k)[-1], dtype=K.floatx())\n",
    "        scores = scores / K.sqrt(dk)\n",
    "\n",
    "        attention_weights = K.softmax(scores, axis=-1)\n",
    "        output = K.batch_dot(attention_weights, v)\n",
    "\n",
    "        return output\n",
    "from tensorflow.keras.layers import AdditiveAttention, Concatenate, Dense, Embedding, Input, LSTM\n",
    "from tensorflow.keras.models import Model\n",
    " \n",
    "# Encoder\n",
    "encoder_inputs = Input(shape=(max_input_length,))\n",
    "encoder_embedding = Embedding(input_vocab_size, 256)(encoder_inputs)\n",
    "encoder_lstm = LSTM(256, return_sequences=True, return_state=True)\n",
    "encoder_outputs, state_h, state_c = encoder_lstm(encoder_embedding)\n",
    "encoder_states = [state_h, state_c]\n",
    " \n",
    "# Decoder\n",
    "decoder_inputs = Input(shape=(max_output_length - 1,))\n",
    "decoder_embedding = Embedding(output_vocab_size, 256)(decoder_inputs)\n",
    "decoder_lstm = LSTM(256, return_sequences=True, return_state=True)\n",
    "decoder_outputs, _, _ = decoder_lstm(decoder_embedding, initial_state=encoder_states)\n",
    " \n",
    "# Attention: decoder attends to encoder outputs\n",
    "self_attention = SelfAttention()\n",
    "attention_output = self_attention(\n",
    "    [decoder_outputs, encoder_outputs, encoder_outputs]\n",
    ")\n",
    "\n",
    " \n",
    "# Combine decoder outputs with attention context\n",
    "decoder_concat = Concatenate(axis=-1)([decoder_outputs, attention_output])\n",
    " \n",
    "# Final Dense layer\n",
    "decoder_dense = Dense(output_vocab_size, activation='softmax')\n",
    "decoder_outputs = decoder_dense(decoder_concat)\n",
    " \n",
    "# Full Model\n",
    "model = Model([encoder_inputs, decoder_inputs], decoder_outputs)\n",
    "model.compile(optimizer='adagrad', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    " \n",
    "# Summary\n",
    "model.summary()\n",
    "\n",
    "\n",
    "# Step 6: Train the Model\n",
    "history_glorot_adam = model.fit([input_sequences, decoder_input_data], decoder_output_data, epochs=100, batch_size=16)\n",
    "\n",
    "# Plotting training loss\n",
    "import matplotlib.pyplot as plt\n",
    "plt.plot(history_glorot_adam.history['loss'])\n",
    "plt.title('Training Loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Double-click <b>here</b> for the solution.\n",
    "\n",
    "<!-- Your answer is below:\n",
    "\n",
    "#Full Model\n",
    "model = Model([encoder_inputs, decoder_inputs], decoder_outputs)\n",
    "model.compile(optimizer='adagrad', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "\n",
    "#Step 6: Train the Model\n",
    "history_adagrad = model.fit([input_sequences, decoder_input_data], decoder_output_data, epochs=100, batch_size=16)\n",
    "\n",
    "#Plotting training losses for glorot_uniform and he_uniform inititalizers\n",
    "import matplotlib.pyplot as plt\n",
    "plt.plot(history_glorot_adam.history['loss'], label=\"adam\", color='red')\n",
    "plt.plot(history_adagrad.history['loss'], label=\"adagrad\", color='blue')\n",
    "plt.title('Training Loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "-->\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Thank you for completing this lab!\n",
    "\n",
    "This notebook was created by [Aman Aggarwal](https://www.linkedin.com/in/aggarwal-aman/). I hope you found this lab interesting and educational. Feel free to contact me if you have any questions!\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!--\n",
    "## Change Log\n",
    "\n",
    "|  Date (YYYY-MM-DD) |  Version | Changed By  |  Change Description |\n",
    "|---|---|---|---|\n",
    "| 2024-11-20  | 1.0  | Aman  |  Created the lab |\n",
    "<hr>\n",
    "-->\n",
    "## <h3 align=\"center\"> © IBM Corporation. All rights reserved. <h3/>\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "prev_pub_hash": "5fac206fee3501f309f0ad0fda5e97953a5edebce9764f906fd3b0da3a932a92",
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
